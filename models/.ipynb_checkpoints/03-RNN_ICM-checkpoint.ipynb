{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# RNN as ICM\n",
    "\n",
    "Recurrent neural network as info causal models. 如何把 RNN 理解成一个信息因果模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "## 从简单的RNN出发\n",
    "\n",
    "[Pytorch 官方教程例子](https://colab.research.google.com/drive/1MFSWJtQ3vzqAxYsCprsWaWSwPZ7ol8L1) 名字分类。\n",
    "\n",
    "- 总共三个节点，输入节点，隐变量节点和输出节点。\n",
    "\n",
    "We will be building and training a basic character-level RNN to classify words. This tutorial, along with the following two, show how to do preprocess data for NLP modeling “from scratch”, in particular not using many of the convenience functions of torchtext, so you can see how preprocessing for NLP modeling works at a low level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"98pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 98.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 94,-184 94,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- h -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>h</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\">h</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;h -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;h</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.65,-144.76C50.29,-136.28 44.85,-125.71 39.96,-116.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"42.99,-114.44 35.3,-107.15 36.77,-117.64 42.99,-114.44\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.29,-144.18C74.33,-133.94 78.94,-120.46 81,-108 83.61,-92.21 83.61,-87.79 81,-72 79.54,-63.14 76.78,-53.77 73.86,-45.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"77.06,-43.97 70.29,-35.82 70.5,-46.41 77.06,-43.97\"/>\n",
       "</g>\n",
       "<!-- h&#45;&gt;h -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>h&#45;&gt;h</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.9,-102.43C59.69,-105.68 72,-101.53 72,-90 72,-81.62 65.5,-77.14 57.04,-76.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"56.5,-73.1 46.9,-77.57 57.19,-80.07 56.5,-73.1\"/>\n",
       "</g>\n",
       "<!-- h&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>h&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1128a1550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例子 \n",
    "# https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "from graphviz import Source\n",
    "Source('digraph{rankdir=TD; x -> h -> y, h; x-> y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "对应着一个信息充分流动（也就是）的信息因果模型为 \n",
    "\n",
    "- $(H^c, h^c, h^c_{in})$ where $h^c=h$ and $H^c \\sim \\delta(\\cdot; x^c, h^c)$.\n",
    "- $(Y^c, y^c, y^c_{in})$ where $y^c_{in} = (h^c, x^c)$, $Y^c \\sim softmax(\\cdot; x^c, h^c)$\n",
    "\n",
    "For 干预序列 $(\\sigma_{hy}(h^c_t), do(x_t)$(考虑到特殊情况，该干预等价于 $do(h, x)$), $y, h$ accept the information and update node state $(y^c, h^c)$. 但是收到信息之后的节点并没有发出信息，也就是发出门控全部为0，而接收信息门控全部打开。\n",
    "\n",
    "\n",
    "- 如何某个节点是确定性, dirac 分布的节点，例如 $h$， 那么 $do(h)$ 的功能就仅仅把当前 node state 传递给其子节点。\n",
    "- 所谓的 predictive coding 本质类似 state of edges，但是不是 state of edges. 且别在于边是信道，并不存储信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "模型分布和指导分布\n",
    "\n",
    "```python\n",
    "# model and guide?\n",
    "def model(data, pred_coding, intervene):\n",
    "    # 干预对模型的影响，结果是一个与干预是什么有关的随机变量\n",
    "    # 每次信息干预得到随机变量应该都大概率具备测量值 $x$\n",
    "    intervene on model # 某种外部干预\n",
    "    \n",
    "    if sended and accepted: # 门控1确定是否发出信息；门控2确定是否接收信息\n",
    "        update predictive coding\n",
    "        \n",
    "    while any update:\n",
    "        抽样，也就是测量\n",
    "        if sended and accepted: # 门控1确定是否发出信息；门控2确定是否接收信息\n",
    "            update predictive coding\n",
    "        \n",
    "    return pred_coding_new\n",
    "    \n",
    "def gude(data, pred_coding, intervene):\n",
    "    # 找到合适干预使得容易得到我们想要的样本\n",
    "    post_intervene <- intervene|data # amortization\n",
    "    post_intervene on model # 某种外部干预\n",
    "    \n",
    "    if sended and accepted: # 门控1确定是否发出信息；门控2确定是否接收信息\n",
    "        update predictive coding\n",
    "     \n",
    "    while any update:\n",
    "        抽样，也就是测量\n",
    "        if sended and accepted: # 门控1确定是否发出信息；门控2确定是否接收信息\n",
    "            update predictive coding\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## RNN written as ICM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "首先是得到数据的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# urllib.request.urlretrieve('https://download.pytorch.org/tutorial/data.zip', 'data.zip')\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 数据输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Czech.txt', 'data/names/German.txt', 'data/names/Arabic.txt', 'data/names/Japanese.txt', 'data/names/Chinese.txt', 'data/names/Vietnamese.txt', 'data/names/Russian.txt', 'data/names/French.txt', 'data/names/Irish.txt', 'data/names/English.txt', 'data/names/Spanish.txt', 'data/names/Greek.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Scottish.txt', 'data/names/Dutch.txt', 'data/names/Korean.txt', 'data/names/Polish.txt']\n",
      "Slusarski\n",
      "18\n",
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import glob, os, unicodedata, string, math, time\n",
    "from io import open\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# import urllib.request\n",
    "# urllib.request.urlretrieve('https://download.pytorch.org/tutorial/data.zip', 'data.zip')\n",
    "# !unzip data.zip\n",
    "\n",
    "def findFiles(path): \n",
    "    return glob.glob(path)\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "n_categories = len(all_categories)\n",
    "print(n_categories)\n",
    "print(category_lines['Italian'][:5])\n",
    "\n",
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 建模模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 57]) torch.Size([1, 18])\n",
      "('Vietnamese', 5)\n",
      "名字类别 = Russian / 对应名字 = Dahin\n",
      "名字类别 = Dutch / 对应名字 = Peter\n",
      "名字类别 = Arabic / 对应名字 = Kattan\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(input.shape, output.shape)\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "print(categoryFromOutput(output))\n",
    "\n",
    "import random\n",
    "def randomChoice(l): # 选择一个样本\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "for i in range(3):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('名字类别 =', category, '/ 对应名字 =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 25% (0m 18s) 2.7282 Exley / Irish ✗ (English)\n",
      "10000 50% (0m 36s) 4.6078 Lis / Korean ✗ (Polish)\n",
      "15000 75% (0m 54s) 2.0643 Melendez / Dutch ✗ (Spanish)\n",
      "20000 100% (1m 11s) 1.2555 Paulissen / Dutch ✓\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005 \n",
    "def train(category_tensor, line_tensor): # 每次训练用一个样本\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    return output, loss.item()\n",
    "\n",
    "n_iters = 20000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    return output\n",
    "\n",
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# plt.plot(all_losses)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
