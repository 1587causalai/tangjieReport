{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "重要知识点：\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- 动态控制随机函数\n",
    "\n",
    "这样随机函数有一个特点，那就是任何一个样本，它的维度是不确定的，你无法计算部分观测的概率。也是由于其样本是动态生成的，定义指导分布的时候，无法定义一个抽样语句与模型分布中每个隐变量对应。所以也无法用那些推断算法，需要想其他办法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# ICM with One Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "一个节点的信息因果模型 with a loop 是最简单的。We consider an Info Causal Model(ICM) with the causal graph $G=(V, E)$ where $V = \\{X\\}$ and $E=\\{[X, X]\\}$. 我们本文的目的是希望用这个最简单的模型阐述清楚 ICM 的构建，训练，和推断(causal and statistical inference)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"80pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 80.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 76,-40 76,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.44,-24.69C63.03,-25.15 72,-22.92 72,-18 72,-14.77 68.14,-12.7 62.49,-11.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.6,-8.29 52.44,-11.31 62.27,-15.28 62.6,-8.29\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1115f0550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "Source('digraph{X->X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "作为一个简单的 feedback system, 表面上看很简单，但是如果我们允许 $X$ 是一个复杂内部结构的张量，那么任何反馈系统都可以抽样成这种形式。因此我们需要研究在此简单模型上的因果推断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "\n",
    "# Set matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Data\n",
    "DATA_URL = \"https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\"\n",
    "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont_africa</th>\n",
       "      <th>rugged</th>\n",
       "      <th>rgdppc_2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858</td>\n",
       "      <td>7.492609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.427</td>\n",
       "      <td>8.216929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769</td>\n",
       "      <td>9.933263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>9.407032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.688</td>\n",
       "      <td>7.792343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont_africa  rugged  rgdppc_2000\n",
       "2            1   0.858     7.492609\n",
       "4            0   3.427     8.216929\n",
       "7            0   0.769     9.933263\n",
       "8            0   0.775     9.407032\n",
       "9            0   2.688     7.792343"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Model\n",
    "\n",
    "先把一个节点的模型搭建起来。\n",
    "\n",
    "- 思路一，对比RNN。序列信息输入，得到一个结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import math, os, torch, pyro\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "data = []\n",
    "data.extend([torch.tensor(1.0) for _ in range(6)])\n",
    "data.extend([torch.tensor(0.0) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"80pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 80.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 76,-40 76,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.44,-24.69C63.03,-25.15 72,-22.92 72,-18 72,-14.77 68.14,-12.7 62.49,-11.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.6,-8.29 52.44,-11.31 62.27,-15.28 62.6,-8.29\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1115f0550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "Source('digraph{X->X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "我们发现 `model` 会调用多次，无法对最后一个随机变量条件化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, preditive coding 0.0 and control 1.0\n",
      "step 2, updated preditive coding -1.2103749513626099 and control 1.0\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    x_c = torch.tensor(0.0)\n",
    "    alpha0, beta0 = torch.tensor(10.0), torch.tensor(10.0)\n",
    "    theta = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    \n",
    "    t = 1\n",
    "    alpha = 0.1\n",
    "    x = pyro.sample(\"sample_{}\".format(t), dist.Normal(x_c, 1))\n",
    "    # 第一个门控通过概率为 theta, 第二门控通过概率为 1.\n",
    "    B = pyro.sample('control_{}'.format(t), dist.Bernoulli(probs=theta))\n",
    "    print(\"step {}, preditive coding {} and control {}\".format(t, x_c.item(), B.item()))\n",
    "    \n",
    "    while B:\n",
    "        t = t + 1\n",
    "        x_c = alpha * x_c + (1 - alpha) * x # 更新预测编码\n",
    "        print(\"step {}, updated preditive coding {} and control {}\".format(t, x_c.item(), B.item()))\n",
    "        B = pyro.sample('control_{}'.format(t), dist.Bernoulli(probs=theta)) # 门控\n",
    "        x = pyro.sample(\"sample_{}\".format(t), dist.Normal(x_c, 1)) # 抽样\n",
    "\n",
    "    return x, t\n",
    "\n",
    "\n",
    "cond_data = {\"x_{}\".format(t): torch.tensor(1.0)}\n",
    "cond_model = poutine.condition(model, data={\"x_{}\".format(model()[-1]): torch.tensor(1.0)})\n",
    "# trace = poutine.trace(cond_model).get_trace()\n",
    "# trace.nodes\n",
    "# 想对最后一个 sample site 条件化，失败了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "但是，一种特殊情况是可以对最后一个变量条件化的，那就是门控独立于样本抽样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, preditive coding 0.0 and control 1.0\n",
      "None\n",
      "Current x_c tensor(0.)\n",
      "step 2, updated preditive coding 1.7503198385238647 and control 1.0\n",
      "{'x_2': tensor(1.)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_items([('_INPUT', {'name': '_INPUT', 'type': 'args', 'args': (tensor(1.),), 'kwargs': {}}), ('latent_fairness', {'type': 'sample', 'name': 'latent_fairness', 'fn': Beta(), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.6435), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('sample_1', {'type': 'sample', 'name': 'sample_1', 'fn': Normal(loc: 0.0, scale: 1.0), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(1.9448), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('control_1', {'type': 'sample', 'name': 'control_1', 'fn': Bernoulli(probs: 0.6434524655342102), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(1.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('control_2', {'type': 'sample', 'name': 'control_2', 'fn': Bernoulli(probs: 0.6434524655342102), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('sample_2', {'type': 'sample', 'name': 'sample_2', 'fn': Normal(loc: 1.7503198385238647, scale: 1.0), 'is_observed': True, 'args': (), 'kwargs': {}, 'value': {'x_2': tensor(1.)}, 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('_RETURN', {'name': '_RETURN', 'type': 'return', 'value': ({'x_2': tensor(1.)}, 2)})])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(obs):\n",
    "    x_c = torch.tensor(0.0)\n",
    "    alpha0, beta0 = torch.tensor(10.0), torch.tensor(10.0)\n",
    "    theta = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    \n",
    "    t = 1\n",
    "    alpha = 0.1\n",
    "    x = pyro.sample(\"sample_{}\".format(t), dist.Normal(x_c, 1))\n",
    "    # 第一个门控通过概率为 theta, 第二门控通过概率为 1.\n",
    "    B = pyro.sample('control_{}'.format(t), dist.Bernoulli(probs=theta))\n",
    "    print(\"step {}, preditive coding {} and control {}\".format(t, x_c.item(), B.item()))\n",
    "    data = None if B else {\"x_{}\".format(t): obs}\n",
    "    print(data)\n",
    "    \n",
    "    while B:\n",
    "        t = t + 1\n",
    "        print('Current x_c', x_c)\n",
    "        x_c = alpha * x_c + (1 - alpha) * x # 更新预测编码\n",
    "        print(\"step {}, updated preditive coding {} and control {}\".format(t, x_c.item(), B.item()))\n",
    "        B = pyro.sample('control_{}'.format(t), dist.Bernoulli(probs=theta)) # 门控\n",
    "        \n",
    "        data = None if B else {\"x_{}\".format(t): torch.tensor(1.0)}\n",
    "        print(data)\n",
    "        x = pyro.sample(\"sample_{}\".format(t), dist.Normal(x_c, 1), obs=data) # 抽样\n",
    "\n",
    "    return x, t\n",
    "\n",
    "obs = torch.tensor(1.0)\n",
    "trace = poutine.trace(model).get_trace(obs)\n",
    "trace.nodes.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这个随机函数有一个特点，那就是任何一个样本，它的维度是不确定的，你无法计算部分观测的概率。也是由于其样本是动态生成的，定义指导分布的时候，无法定义一个抽样语句与模型分布中每个隐变量对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "{'x_2': tensor(52)}\n",
      "x_0 {'type': 'sample', 'name': 'x_0', 'fn': Bernoulli(probs: 0.5), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}\n",
      "x_1 {'type': 'sample', 'name': 'x_1', 'fn': Bernoulli(probs: 0.5), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}\n",
      "x_2 {'type': 'sample', 'name': 'x_2', 'fn': Bernoulli(probs: 0.5), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(1.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.0794)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyro.poutine as poutine\n",
    "import pyro.distributions as dist\n",
    "from pyro.poutine.trace_messenger import TraceMessenger\n",
    "from pyro.poutine.condition_messenger import ConditionMessenger\n",
    "\n",
    "def geometric(p, t=None):\n",
    "    t = 0 if t is None else t\n",
    "    # 该函数表示第 t 次失败之后, 继续尝试直到成功，返回总共失败次数。\n",
    "    x = pyro.sample(\"x_{}\".format(t), pyro.distributions.Bernoulli(p))\n",
    "    if x.item() == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        t_update = t+1\n",
    "        return 1+geometric(p, t_update)\n",
    "\n",
    "print(geometric(0.1))\n",
    "\n",
    "cond_data = {\"last\": torch.tensor(52)}\n",
    "\n",
    "with TraceMessenger() as tracer:\n",
    "    cond_data = {\"x_{}\".format(geometric(0.5)):v for k, v in cond_data.items()}\n",
    "\n",
    "print(cond_data)\n",
    "trace = tracer.trace\n",
    "logp = 0.\n",
    "for name, node in trace.nodes.items():\n",
    "    print(name, node)\n",
    "    if node[\"type\"] == \"sample\":\n",
    "        if node[\"is_observed\"]:\n",
    "            assert node[\"value\"] is cond_data[name]\n",
    "            print('观测变量', node)\n",
    "        logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "\n",
    "logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 尝试一:门控独立于样本 \n",
    "\n",
    "模型是这样的： theta 是门控的概率，具备先验分布 `dist.Beta(alpha0, beta0)`.\n",
    "\n",
    "有了一个数据之后，请问 $theta$ 的后验分布是什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, preditive coding 0.0 and control 1.0\n",
      "None\n",
      "Current x_c tensor(0.)\n",
      "step 2, updated preditive coding 0.5402063727378845 and control 1.0\n",
      "{'x_2': tensor(1.)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_items([('_INPUT', {'name': '_INPUT', 'type': 'args', 'args': (tensor(1.),), 'kwargs': {}}), ('latent_fairness', {'type': 'sample', 'name': 'latent_fairness', 'fn': Beta(), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.3170), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('sample_1', {'type': 'sample', 'name': 'sample_1', 'fn': Normal(loc: 0.0, scale: 1.0), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.6002), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('control_1', {'type': 'sample', 'name': 'control_1', 'fn': Bernoulli(probs: 0.31696274876594543), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(1.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('control_2', {'type': 'sample', 'name': 'control_2', 'fn': Bernoulli(probs: 0.31696274876594543), 'is_observed': False, 'args': (), 'kwargs': {}, 'value': tensor(0.), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('sample_2', {'type': 'sample', 'name': 'sample_2', 'fn': Normal(loc: 0.5402063727378845, scale: 1.0), 'is_observed': True, 'args': (), 'kwargs': {}, 'value': {'x_2': tensor(1.)}, 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None}), ('_RETURN', {'name': '_RETURN', 'type': 'return', 'value': ({'x_2': tensor(1.)}, 2)})])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(obs):\n",
    "    x_c = torch.tensor(0.0)\n",
    "    alpha0, beta0 = torch.tensor(10.0), torch.tensor(10.0)\n",
    "    theta = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    \n",
    "    t = 1\n",
    "    alpha = 0.1\n",
    "    x = pyro.sample(\"sample_{}\".format(t), dist.Normal(x_c, 1))\n",
    "    # 第一个门控通过概率为 theta, 第二门控通过概率为 1.\n",
    "    B = pyro.sample('control_{}'.format(t), dist.Bernoulli(probs=theta))\n",
    "    print(\"step {}, preditive coding {} and control {}\".format(t, x_c.item(), B.item()))\n",
    "    data = None if B else {\"x_{}\".format(t): obs}\n",
    "    print(data)\n",
    "    \n",
    "    while B:\n",
    "        t = t + 1\n",
    "        print('Current x_c', x_c)\n",
    "        x_c = alpha * x_c + (1 - alpha) * x # 更新预测编码\n",
    "        print(\"step {}, updated preditive coding {} and control {}\".format(t, x_c.item(), B.item()))\n",
    "        B = pyro.sample('control_{}'.format(t), dist.Bernoulli(probs=theta)) # 门控\n",
    "        \n",
    "        data = None if B else {\"x_{}\".format(t): torch.tensor(1.0)}\n",
    "        print(data)\n",
    "        x = pyro.sample(\"sample_{}\".format(t), dist.Normal(x_c, 1), obs=data) # 抽样\n",
    "\n",
    "    return x, t\n",
    "\n",
    "obs = torch.tensor(1.0)\n",
    "trace = poutine.trace(model).get_trace(obs)\n",
    "trace.nodes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, preditive coding 0.0 and control 1.0\n",
      "None\n",
      "Current x_c tensor(0.)\n",
      "step 2, updated preditive coding -0.12902162969112396 and control 1.0\n",
      "None\n",
      "Current x_c tensor(-0.1290)\n",
      "step 3, updated preditive coding -0.7264322638511658 and control 1.0\n",
      "{'x_3': tensor(1.)}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error while computing log_prob at site 'sample_3':\nThe value argument to log_prob must be a Tensor\n       Trace Shapes:  \n        Param Sites:  \n       Sample Sites:  \nlatent_fairness dist |\n               value |\n            log_prob |\n       sample_1 dist |\n               value |\n            log_prob |\n      control_1 dist |\n               value |\n            log_prob |\n      control_2 dist |\n               value |\n            log_prob |\n       sample_2 dist |\n               value |\n            log_prob |\n      control_3 dist |\n               value |\n            log_prob |\n       sample_3 dist |\n               value |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                         \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument to log_prob must be a Tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The value argument to log_prob must be a Tensor",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-10e9acbd97f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m     52\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 53\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmodel_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_subsample_sites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_site\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                         raise ValueError(\"Error while computing log_prob at site '{}':\\n{}\\n{}\"\n\u001b[0;32m--> 221\u001b[0;31m                                          .format(name, exc_value, shapes)).with_traceback(traceback)\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unscaled_log_prob\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_and_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"log_prob\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                         \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \"\"\"\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument to log_prob must be a Tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mevent_dim_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error while computing log_prob at site 'sample_3':\nThe value argument to log_prob must be a Tensor\n       Trace Shapes:  \n        Param Sites:  \n       Sample Sites:  \nlatent_fairness dist |\n               value |\n            log_prob |\n       sample_1 dist |\n               value |\n            log_prob |\n      control_1 dist |\n               value |\n            log_prob |\n      control_2 dist |\n               value |\n            log_prob |\n       sample_2 dist |\n               value |\n            log_prob |\n      control_3 dist |\n               value |\n            log_prob |\n       sample_3 dist |\n               value |"
     ]
    }
   ],
   "source": [
    "def guide(obs):\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0), constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0), constraint=constraints.positive)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))\n",
    "    \n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 2000\n",
    "for step in range(n_steps):\n",
    "    svi.step(obs)\n",
    "    if step % 100 == 0:\n",
    "        print('.', end='')\n",
    "\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 模型构建\n",
    "\n",
    "在构建模型之前，我需要进一步熟悉Pyro，从头至尾用因果模型学习一遍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Bayesian 模型 \n",
    "\n",
    "$$\n",
    "\\text{weight} \\sim N(\\mu, 1) \\\\\n",
    "\\text{measurement}|\\text{weight} \\sim N(\\text{weight}, 0.75)\n",
    "$$\n",
    "\n",
    "那么给定观测 $\\text{measurement} = 9.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  9.107474327087402\n",
      "b =  0.6285384893417358\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "\n",
    "pyro.set_rng_seed(101)\n",
    "mu = 8.5\n",
    "\n",
    "def scale(mu):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(mu, 1.0))\n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 0.75))\n",
    "conditioned_scale = pyro.condition(scale, data={\"measurement\": 9.5})\n",
    "\n",
    "def scale_parametrized_guide(mu):\n",
    "    a, b = pyro.param(\"a\", torch.tensor(mu)), pyro.param(\"b\", torch.tensor(1.))\n",
    "    return pyro.sample(\"weight\", dist.Normal(a, torch.abs(b)))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "svi = pyro.infer.SVI(model=conditioned_scale,\n",
    "                     guide=scale_parametrized_guide,\n",
    "                     optim=pyro.optim.SGD({\"lr\": 0.001, \"momentum\":0.1}),\n",
    "                     loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "\n",
    "losses, a,b  = [], [], []\n",
    "num_steps = 2500\n",
    "for t in range(num_steps):\n",
    "    losses.append(svi.step(mu))\n",
    "    a.append(pyro.param(\"a\").item())\n",
    "    b.append(pyro.param(\"b\").item())\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"ELBO\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\");\n",
    "print('a = ',pyro.param(\"a\").item())\n",
    "print('b = ', pyro.param(\"b\").item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 几何分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "p = pyro.sample('p', pyro.distributions.Uniform(0, 1))\n",
    "def geometric(p, t=0):\n",
    "    # 该函数表示第 t 次失败之后, 继续尝试直到成功，返回总共失败次数。\n",
    "    x = pyro.sample(\"x_{}\".format(t), pyro.distributions.Bernoulli(p))\n",
    "    if x.item() == 1:\n",
    "        return t\n",
    "    else:\n",
    "        t_update = t+1\n",
    "        return 1 + geometric(p, t_update)\n",
    "\n",
    "print(geometric(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8346), tensor(0.4489))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc, scale = 0.0, 1.0\n",
    "u = pyro.sample('U', pyro.distributions.Uniform(0, 1))\n",
    "y = pyro.sample('Y', pyro.distributions.Normal(loc, scale))\n",
    "u, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, tensor(-0.2728))"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc, scale = 0.0, 4.0\n",
    "obs = torch.tensor(1.0)\n",
    "def model(loc, scale):\n",
    "    t = 0\n",
    "    theta = pyro.param(\"theta\", torch.tensor(2.0))\n",
    "    while t < 100000:\n",
    "        t = t + 1\n",
    "        u = pyro.sample('u_{}'.format(t), pyro.distributions.Uniform(0, 1))\n",
    "        y = pyro.sample('y_{}'.format(t), pyro.distributions.Normal(loc, scale))\n",
    "        if y**2 < u**2 / theta:\n",
    "            # 此时需要条件化 y_t with obs\n",
    "            break            \n",
    "    return t, y\n",
    "\n",
    "x = model(loc, scale)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha_q', 'beta_q', 'theta']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in pyro.get_param_store()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 掷硬币案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline=True\n",
      "..\n",
      "Did 128 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7989 & 0.7426\n",
      "Doing inference with use_decaying_avg_baseline=False\n",
      "........\n",
      "Did 732 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7674 & 0.7989\n"
     ]
    }
   ],
   "source": [
    "import os, torch, pyro, sys\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "from pyro.distributions.testing.fakes import NonreparameterizedBeta\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "class BernoulliBetaExample:\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha0 = 10.0\n",
    "        self.beta0 = 10.0\n",
    "        self.data = torch.zeros(10)\n",
    "        self.data[0:6] = torch.ones(6)\n",
    "        self.n_data = self.data.size(0)\n",
    "        self.alpha_n = self.data.sum() + self.alpha0\n",
    "        self.beta_n = - self.data.sum() + torch.tensor(self.beta0 + self.n_data)\n",
    "        self.alpha_q_0 = 15.0\n",
    "        self.beta_q_0 = 15.0\n",
    "\n",
    "    def model(self, use_decaying_avg_baseline):\n",
    "        f = pyro.sample(\"latent_fairness\", dist.Beta(self.alpha0, self.beta0))\n",
    "        with pyro.plate(\"data_plate\"):\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(f), obs=self.data)\n",
    "    def guide(self, use_decaying_avg_baseline):\n",
    "        alpha_q = pyro.param(\"alpha_q\", torch.tensor(self.alpha_q_0), constraint=constraints.positive)\n",
    "        beta_q = pyro.param(\"beta_q\", torch.tensor(self.beta_q_0), constraint=constraints.positive)\n",
    "        baseline_dict = {'use_decaying_avg_baseline': use_decaying_avg_baseline, 'baseline_beta': 0.90}\n",
    "        pyro.sample(\"latent_fairness\", NonreparameterizedBeta(alpha_q, beta_q), infer=dict(baseline=baseline_dict))\n",
    "\n",
    "    def do_inference(self, use_decaying_avg_baseline, tolerance=0.80):\n",
    "        pyro.clear_param_store()\n",
    "        optimizer = optim.Adam({\"lr\": .0005, \"betas\": (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline=%s\" % use_decaying_avg_baseline)\n",
    "\n",
    "        param_abs_error = lambda name, target: torch.sum(torch.abs(target - pyro.param(name))).item()\n",
    "        for k in range(self.max_steps):\n",
    "            svi.step(use_decaying_avg_baseline)\n",
    "            if k % 100 == 0:\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            alpha_error = param_abs_error(\"alpha_q\", self.alpha_n)\n",
    "            beta_error = param_abs_error(\"beta_q\", self.beta_n)\n",
    "\n",
    "            if alpha_error < tolerance and beta_error < tolerance:\n",
    "                break\n",
    "\n",
    "        print(\"\\nDid %d steps of inference.\" % k)\n",
    "        print((\"Final absolute errors for the two variational parameters \" +\n",
    "               \"were %.4f & %.4f\") % (alpha_error, beta_error))\n",
    "\n",
    "bbe = BernoulliBetaExample(max_steps=1000)\n",
    "bbe.do_inference(use_decaying_avg_baseline=True)\n",
    "bbe.do_inference(use_decaying_avg_baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 拒绝抽样模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "需要采样 $p(x) = c \\cdot g(x) \\cdot h(x), Y \\sim h(x), U\\sim U(0, 1)$. \n",
    "\n",
    "按照 Structural Causal Model(SCM) 结构因果方程的思维 , $U$ 的取值会影响 $X$ 的取值，然后这不是事实，$X$ 的具体取值的大小完全取决于 $Y$，但是其分布却与 $U$ 的分布有关，相当某种选择偏差导致的分布变化。 所以我们理解结构因果方程时候， 更新方程是 $X \\leftarrow Y, Y \\sim h(x)$，而 $U$ 控制是否更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"162pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 162.11 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 158.11,-40 158.11,4 -4,4\"/>\n",
       "<!-- Y -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"127.11\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.11\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Y&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.03,-18C65.01,-18 77.98,-18 89.86,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.95,-21.5 99.95,-18 89.95,-14.5 89.95,-21.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.06\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">U</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x132860fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "Source('digraph{rankdir=LR; Y -> X[label=\"U\"]}')\n",
    "# ![reject.png](https://i.loli.net/2020/04/01/WyshxgO3X5moDTA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "具体的采样原理见：\n",
    "\n",
    "<img width=300 src=\"https://i.loli.net/2020/04/01/WyshxgO3X5moDTA.png\" > </img>\n",
    "\n",
    "具体算法如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6984, tensor(-0.0415))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc, scale = 10.0, 4.0\n",
    "obs = torch.tensor(1.0)\n",
    "def model(loc, scale):\n",
    "    t = 0\n",
    "    theta = 100\n",
    "    while t < 10000:\n",
    "        t = t + 1\n",
    "        u = pyro.sample('u_{}'.format(t), pyro.distributions.Uniform(0, 1))\n",
    "        y = pyro.sample('y_{}'.format(t), pyro.distributions.Normal(loc, scale))\n",
    "        if y**2 < u**2 / theta:\n",
    "            # 此时需要条件化 y_t with obs\n",
    "            break     \n",
    "    if t >= 10000:\n",
    "        print(\"Hit the max iteration!\")\n",
    "    return t, y\n",
    "\n",
    "x = model(loc, scale)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os, torch, pyro, sys\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "from pyro.distributions.testing.fakes import NonreparameterizedBeta\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline=True\n",
      "..\n",
      "Did 186 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7994 & 0.7861\n",
      "Doing inference with use_decaying_avg_baseline=False\n",
      ".....\n",
      "Did 448 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7969 & 0.7989\n"
     ]
    }
   ],
   "source": [
    "class RejectSampling(object):\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def model(self, use_decaying_avg_baseline):\n",
    "        f = pyro.sample(\"control\", dist.Uniform(0, 1))\n",
    "        with pyro.plate(\"data_plate\"):\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(f), obs=self.data)\n",
    "    def guide(self, use_decaying_avg_baseline):\n",
    "        alpha_q = pyro.param(\"alpha_q\", torch.tensor(self.alpha_q_0), constraint=constraints.positive)\n",
    "        beta_q = pyro.param(\"beta_q\", torch.tensor(self.beta_q_0), constraint=constraints.positive)\n",
    "        baseline_dict = {'use_decaying_avg_baseline': use_decaying_avg_baseline, 'baseline_beta': 0.90}\n",
    "        pyro.sample(\"latent_fairness\", NonreparameterizedBeta(alpha_q, beta_q), infer=dict(baseline=baseline_dict))\n",
    "\n",
    "    def do_inference(self, use_decaying_avg_baseline, tolerance=0.80):\n",
    "        pyro.clear_param_store()\n",
    "        optimizer = optim.Adam({\"lr\": .0005, \"betas\": (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline=%s\" % use_decaying_avg_baseline)\n",
    "\n",
    "        param_abs_error = lambda name, target: torch.sum(torch.abs(target - pyro.param(name))).item()\n",
    "        for k in range(self.max_steps):\n",
    "            svi.step(use_decaying_avg_baseline)\n",
    "            if k % 100 == 0:\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            alpha_error = param_abs_error(\"alpha_q\", self.alpha_n)\n",
    "            beta_error = param_abs_error(\"beta_q\", self.beta_n)\n",
    "\n",
    "            if alpha_error < tolerance and beta_error < tolerance:\n",
    "                break\n",
    "\n",
    "        print(\"\\nDid %d steps of inference.\" % k)\n",
    "        print((\"Final absolute errors for the two variational parameters \" +\n",
    "               \"were %.4f & %.4f\") % (alpha_error, beta_error))\n",
    "\n",
    "g = BernoulliBetaExample(max_steps=1000)\n",
    "g.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Mini-Pyro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Mini-pyro 例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "\n",
    "from pyro.generic import distributions as dist\n",
    "# We use the pyro.generic interface to support dynamic choice of backend.\n",
    "from pyro.generic import infer, ops, optim, pyro, pyro_backend\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # Define a basic model with a single Normal latent random variable `loc`\n",
    "    # and a batch of Normally distributed observations.\n",
    "    def model(data):\n",
    "        loc = pyro.sample(\"loc\", dist.Normal(0., 1.))\n",
    "        with pyro.plate(\"data\", len(data), dim=-1):\n",
    "            pyro.sample(\"obs\", dist.Normal(loc, 1.), obs=data)\n",
    "\n",
    "    # Define a guide (i.e. variational distribution) with a Normal\n",
    "    # distribution over the latent random variable `loc`.\n",
    "    def guide(data):\n",
    "        guide_loc = pyro.param(\"guide_loc\", torch.tensor(0.))\n",
    "        guide_scale = ops.exp(pyro.param(\"guide_scale_log\", torch.tensor(0.)))\n",
    "        pyro.sample(\"loc\", dist.Normal(guide_loc, guide_scale))\n",
    "\n",
    "    # Generate some data.\n",
    "    torch.manual_seed(0)\n",
    "    data = torch.randn(100) + 3.0\n",
    "\n",
    "    # Because the API in minipyro matches that of Pyro proper,\n",
    "    # training code works with generic Pyro implementations.\n",
    "    with pyro_backend(args.backend):\n",
    "        # Construct an SVI object so we can do variational inference on our\n",
    "        # model/guide pair.\n",
    "        Elbo = infer.JitTrace_ELBO if args.jit else infer.Trace_ELBO\n",
    "        elbo = Elbo()\n",
    "        adam = optim.Adam({\"lr\": args.learning_rate})\n",
    "        svi = infer.SVI(model, guide, adam, elbo)\n",
    "\n",
    "        # Basic training loop\n",
    "        pyro.get_param_store().clear()\n",
    "        for step in range(args.num_steps):\n",
    "            loss = svi.step(data)\n",
    "            if step % 100 == 0:\n",
    "                print(\"step {} loss = {}\".format(step, loss))\n",
    "\n",
    "        # Report the final values of the variational parameters\n",
    "        # in the guide after training.\n",
    "        for name in pyro.get_param_store():\n",
    "            value = pyro.param(name)\n",
    "            print(\"{} = {}\".format(name, value.detach().cpu().numpy()))\n",
    "\n",
    "        # For this simple (conjugate) model we know the exact posterior. In\n",
    "        # particular we know that the variational distribution should be\n",
    "        # centered near 3.0. So let's check this explicitly.\n",
    "        assert (pyro.param(\"guide_loc\") - 3.0).abs() < 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 计算对数似然"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pyro.poutine as poutine\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def make_log_joint(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "from pyro.poutine.trace_messenger import TraceMessenger\n",
    "from pyro.poutine.condition_messenger import ConditionMessenger \n",
    "\n",
    "def make_log_joint_2(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        with TraceMessenger() as tracer:\n",
    "            with ConditionMessenger(data=cond_data):\n",
    "                model(*args, **kwargs)\n",
    "        \n",
    "        trace = tracer.trace\n",
    "        logp = 0.\n",
    "        for name, node in trace.nodes.items():\n",
    "            if node[\"type\"] == \"sample\":\n",
    "                if node[\"is_observed\"]:\n",
    "                    assert node[\"value\"] is cond_data[name]\n",
    "                logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "        return logp\n",
    "    return _log_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.2637)\n"
     ]
    }
   ],
   "source": [
    "def weather():\n",
    "    cloudy = pyro.sample('cloudy', pyro.distributions.Bernoulli(0.3))\n",
    "    cloudy = 'cloudy' if cloudy.item() == 1.0 else 'sunny'\n",
    "    mean_temp = {'cloudy': 55.0, 'sunny': 75.0}[cloudy]\n",
    "    scale_temp = {'cloudy': 10.0, 'sunny': 15.0}[cloudy]\n",
    "    temp = pyro.sample('temp', pyro.distributions.Normal(mean_temp, scale_temp))\n",
    "    return cloudy, temp.item()\n",
    "\n",
    "weight_log_joint = make_log_joint(weather)\n",
    "print(weight_log_joint({\"temp\": torch.tensor(51)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 tensor(0.0642)\n",
      "{'temp': tensor(51.5000)}\n",
      "{'y_8': tensor(51.5000)}\n",
      "tensor(-261.4502)\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    loc, scale = 0.0, 4.0\n",
    "    t = 0\n",
    "    theta = pyro.param(\"theta\", torch.tensor(2.0))\n",
    "    while t < 100000:\n",
    "        t = t + 1\n",
    "        u = pyro.sample('u_{}'.format(t), pyro.distributions.Uniform(0, 1))\n",
    "        y = pyro.sample('y_{}'.format(t), pyro.distributions.Normal(loc, scale))\n",
    "        if y**2 < u**2 / theta:\n",
    "            # 此时需要条件化 y_t with obs\n",
    "            break            \n",
    "    return t, y\n",
    "\n",
    "def make_log_joint(model):\n",
    "    t, y = model()\n",
    "    name = \"y_{}\".format(t)\n",
    "    print(t, y)\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        print(cond_data)\n",
    "        cond_data = {name:v for k, v in cond_data.items()}\n",
    "        print(cond_data)\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "model_log_joint = make_log_joint(model)\n",
    "print(model_log_joint({\"temp\": torch.tensor(51.5)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "原始代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sunny', 100.9456787109375)\n",
      "('sunny', 85.012451171875)\n",
      "('sunny', 61.389869689941406)\n",
      "sunny 83.8826904296875\n",
      "{'temp': tensor(51)}\n",
      "{'y_sunny': tensor(51)}\n",
      "tensor(-4.2058)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error while computing log_prob_sum at site 'weight':\nThe value argument to log_prob must be a Tensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mlog_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                         \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument to log_prob must be a Tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The value argument to log_prob must be a Tensor",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-426-8813abdf5019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mscale_log_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_log_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_log_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"measurement\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m9.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8.23\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-426-8813abdf5019>\u001b[0m in \u001b[0;36m_log_joint\u001b[0;34m(cond_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mconditioned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconditioned_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_log_joint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mlog_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    194\u001b[0m                         \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_site\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                         raise ValueError(\"Error while computing log_prob_sum at site '{}':\\n{}\\n\"\n\u001b[0;32m--> 196\u001b[0;31m                                          .format(name, exc_value, shapes)).with_traceback(traceback)\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_and_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_prob_sum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mlog_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                         \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \"\"\"\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument to log_prob must be a Tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mevent_dim_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error while computing log_prob_sum at site 'weight':\nThe value argument to log_prob must be a Tensor\n"
     ]
    }
   ],
   "source": [
    "def scale(mu):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(mu, 1.0))\n",
    "    out = pyro.sample(\"measurement\", dist.Normal(weight, 0.75))\n",
    "    return out\n",
    "\n",
    "def weather():\n",
    "    cloudy = pyro.sample('cloudy', pyro.distributions.Bernoulli(0.3))\n",
    "    cloudy = 'cloudy' if cloudy.item() == 1.0 else 'sunny'\n",
    "    mean_temp = {'cloudy': 55.0, 'sunny': 75.0}[cloudy]\n",
    "    scale_temp = {'cloudy': 10.0, 'sunny': 15.0}[cloudy]\n",
    "    temp = pyro.sample('temp', pyro.distributions.Normal(mean_temp, scale_temp))\n",
    "    return cloudy, temp.item()\n",
    "\n",
    "for _ in range(3):\n",
    "    print(weather())\n",
    "\n",
    "weight_log_joint = make_log_joint(weather)\n",
    "print(weight_log_joint({\"temp\": torch.tensor(51)}))\n",
    "\n",
    "import pyro.poutine as poutine\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def make_log_joint(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "scale_log_joint = make_log_joint(scale)\n",
    "print(scale_log_joint({\"measurement\": 9.5, \"weight\": 8.23}, 8.5))\n",
    "\n",
    "def model():\n",
    "    loc, scale = 0.0, 4.0\n",
    "    t = 0\n",
    "    theta = pyro.param(\"theta\", torch.tensor(2.0))\n",
    "    while t < 100000:\n",
    "        t = t + 1\n",
    "        u = pyro.sample('u_{}'.format(t), pyro.distributions.Uniform(0, 1))\n",
    "        y = pyro.sample('y_{}'.format(t), pyro.distributions.Normal(loc, scale))\n",
    "        if y**2 < u**2 / theta:\n",
    "            # 此时需要条件化 y_t with obs\n",
    "            break            \n",
    "    return t, y\n",
    "\n",
    "def make_log_joint(model):\n",
    "    t, y = model()\n",
    "    name = \"y_{}\".format(t)\n",
    "    print(t, y)\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        print(cond_data)\n",
    "        cond_data = {name:v for k, v in cond_data.items()}\n",
    "        print(cond_data)\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "model_log_joint = make_log_joint(model)\n",
    "print(model_log_joint({\"temp\": torch.tensor(51.5)}))\n",
    "\n",
    "from pyro.poutine.trace_messenger import TraceMessenger\n",
    "from pyro.poutine.condition_messenger import ConditionMessenger \n",
    "\n",
    "def make_log_joint_2(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        with TraceMessenger() as tracer:\n",
    "            with ConditionMessenger(data=cond_data):\n",
    "                model(*args, **kwargs)\n",
    "        \n",
    "        trace = tracer.trace\n",
    "        logp = 0.\n",
    "        for name, node in trace.nodes.items():\n",
    "            if node[\"type\"] == \"sample\":\n",
    "                if node[\"is_observed\"]:\n",
    "                    assert node[\"value\"] is cond_data[name]\n",
    "                logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "        return logp\n",
    "    return _log_joint\n",
    "\n",
    "scale_log_joint = make_log_joint_2(scale)\n",
    "print(scale_log_joint({\"measurement\": 9.5, \"weight\": 8.23}, 8.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
